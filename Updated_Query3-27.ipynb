{"cells":[{"cell_type":"markdown","id":"89172c27","metadata":{"id":"89172c27"},"source":["#  Query Gaia for WDS entries - parallelized for multiprocessing across multiple cores\n","#### Summer 2022 -> revised in Spring 2023\n","#### Daphne Zakarian"]},{"cell_type":"code","source":["# conda install astroquery\n","!pip install astroquery"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kjU-Qz8Jf8aN","executionInfo":{"status":"ok","timestamp":1681873984380,"user_tz":300,"elapsed":9091,"user":{"displayName":"Daphne Zakarian","userId":"08361727160766317010"}},"outputId":"c2ea3064-111b-4084-bcab-17da7afa98e5"},"id":"kjU-Qz8Jf8aN","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting astroquery\n","  Downloading astroquery-0.4.6-py3-none-any.whl (4.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: astropy>=4.0 in /usr/local/lib/python3.9/dist-packages (from astroquery) (5.2.2)\n","Requirement already satisfied: beautifulsoup4>=4.3.2 in /usr/local/lib/python3.9/dist-packages (from astroquery) (4.11.2)\n","Requirement already satisfied: html5lib>=0.999 in /usr/local/lib/python3.9/dist-packages (from astroquery) (1.1)\n","Collecting pyvo>=1.1\n","  Downloading pyvo-1.4.1-py3-none-any.whl (887 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.9/887.9 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keyring>=4.0\n","  Downloading keyring-23.13.1-py3-none-any.whl (37 kB)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.9/dist-packages (from astroquery) (1.22.4)\n","Requirement already satisfied: requests>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from astroquery) (2.27.1)\n","Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.9/dist-packages (from astropy>=4.0->astroquery) (6.0)\n","Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.9/dist-packages (from astropy>=4.0->astroquery) (23.0)\n","Requirement already satisfied: pyerfa>=2.0 in /usr/local/lib/python3.9/dist-packages (from astropy>=4.0->astroquery) (2.0.0.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4>=4.3.2->astroquery) (2.4)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.9/dist-packages (from html5lib>=0.999->astroquery) (1.16.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from html5lib>=0.999->astroquery) (0.5.1)\n","Requirement already satisfied: importlib-metadata>=4.11.4 in /usr/local/lib/python3.9/dist-packages (from keyring>=4.0->astroquery) (6.3.0)\n","Collecting jeepney>=0.4.2\n","  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jaraco.classes\n","  Downloading jaraco.classes-3.2.3-py3-none-any.whl (6.0 kB)\n","Collecting SecretStorage>=3.2\n","  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.4.3->astroquery) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.4.3->astroquery) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.4.3->astroquery) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.4.3->astroquery) (1.26.15)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.11.4->keyring>=4.0->astroquery) (3.15.0)\n","Requirement already satisfied: cryptography>=2.0 in /usr/local/lib/python3.9/dist-packages (from SecretStorage>=3.2->keyring>=4.0->astroquery) (40.0.1)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from jaraco.classes->keyring>=4.0->astroquery) (9.1.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=4.0->astroquery) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=4.0->astroquery) (2.21)\n","Installing collected packages: jeepney, jaraco.classes, SecretStorage, pyvo, keyring, astroquery\n","Successfully installed SecretStorage-3.3.3 astroquery-0.4.6 jaraco.classes-3.2.3 jeepney-0.8.0 keyring-23.13.1 pyvo-1.4.1\n"]}]},{"cell_type":"code","execution_count":null,"id":"1887a165","metadata":{"id":"1887a165"},"outputs":[],"source":["\n","from astropy.io import ascii\n","from astropy.table import vstack, Table, unique\n","from astropy.coordinates import SkyCoord \n","import astropy.units as u\n","from astropy import table, log\n","from astropy.wcs import WCS\n","from astropy.coordinates import SkyCoord, Distance, Angle\n","from astropy.time import Time\n","from astropy.io import ascii\n","from astroquery.gaia import Gaia\n","from astroquery.utils.tap.model import job\n","from itertools import combinations\n","import multiprocessing\n","from multiprocessing import Queue, Pool, freeze_support, Process\n","import os\n","from IPython.display import display\n","from multiprocessing import set_start_method"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D94j7k2rkgSP","executionInfo":{"status":"ok","timestamp":1681875173523,"user_tz":300,"elapsed":15740,"user":{"displayName":"Daphne Zakarian","userId":"08361727160766317010"}},"outputId":"ae0d5e6a-88da-4616-c0fe-c12711341714"},"id":"D94j7k2rkgSP","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"id":"4426b90f","metadata":{"id":"4426b90f"},"outputs":[],"source":["# path = 'C:/Users/sc36/Documents/DaphneUSNO/NOFS copy-20230218T215456Z-001/NOFS copy/wdstab6-27.ecsv'\n","# wdstab = Table.read(path, header_start=0, data_start=1) \n","\n","path = '/content/drive/MyDrive/NOFS copy/wdstab6-27.ecsv'\n","wdstab = Table.read(path, header_start=0, data_start=1) "]},{"cell_type":"markdown","id":"b155dd96","metadata":{"id":"b155dd96"},"source":["## query_gaia(coordinate, radius)"]},{"cell_type":"code","execution_count":null,"id":"5d1b1392","metadata":{"id":"5d1b1392"},"outputs":[],"source":["def query_gaia(coordinate, radius):\n","\n","    # these column names list the info to pull from Gaia\n","    # if you change this, make sure to change the wds_to_gaia_query() function \n","    # to update that info in the tables themselves!!\n","    column_names = ['source_id', 'ref_epoch', 'ra', 'ra_error', 'dec',\n","        'dec_error', 'parallax', 'parallax_error', 'parallax_over_error','pmra',\n","        'pmra_error', 'pmdec', 'pmdec_error',\n","        'radial_velocity', 'radial_velocity_error',\n","        'astrometric_params_solved', 'visibility_periods_used',\n","        'astrometric_sigma5d_max','ruwe',\n","        'phot_g_mean_mag', 'phot_g_mean_flux_over_error',\n","        'phot_bp_mean_mag', 'phot_bp_mean_flux_over_error',\n","        'phot_rp_mean_mag', 'phot_rp_mean_flux_over_error',\n","        'bp_rp','phot_bp_rp_excess_factor']\n","    \n","    # the columns have to be a string, not a list\n","    # this turns the column list into a string for the query\n","    columns = ''\n","    for column in column_names:\n","        columns += column + ', '\n","    columns =  columns.rstrip(columns[-4])\n","    columns = columns[:len(columns)-2]\n","    columns\n","\n","    # get the degree value for coordinate and radius\n","    ra = coordinate.ra.deg\n","    dec = coordinate.dec.deg\n","    radius = float(radius.to_value(u.deg))\n","\n","    # query base:\n","    query_base = \"\"\"\n","    SELECT {columns}\n","    FROM gaiadr3.gaia_source\n","    WHERE parallax > 1\n","    AND parallax_over_error > 5\n","    AND parallax_error < 2\n","    AND 1 = CONTAINS(\n","    POINT({ra}, {dec}),\n","    CIRCLE(ra, dec, {rad}))\n","\n","    \"\"\"  \n","\n","\n","\n","    # format the query with our specific info\n","    query = query_base.format(columns=columns, ra=ra, dec=dec, rad=radius)\n","\n","    # make the query to gaia and save the results into astropy table\n","    job = Gaia.launch_job_async(query)\n","    job\n","    results = job.get_results()\n","    return results\n"]},{"cell_type":"markdown","id":"71fc4bed","metadata":{"id":"71fc4bed"},"source":["\n","## test queries for individual rows"]},{"cell_type":"code","execution_count":null,"id":"46966bbf","metadata":{"id":"46966bbf","colab":{"base_uri":"https://localhost:8080/","height":210},"executionInfo":{"status":"ok","timestamp":1681883519876,"user_tz":300,"elapsed":2459,"user":{"displayName":"Daphne Zakarian","userId":"08361727160766317010"}},"outputId":"c30e5ac1-47c9-414e-beff-3df18eee12fb"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:astroquery:Query finished.\n"]},{"output_type":"stream","name":"stdout","text":["INFO: Query finished. [astroquery.utils.tap.core]\n"]},{"output_type":"stream","name":"stderr","text":["INFO:astroquery:Query finished.\n"]},{"output_type":"stream","name":"stdout","text":["INFO: Query finished. [astroquery.utils.tap.core]\n"]},{"output_type":"execute_result","data":{"text/plain":["<Table length=0>\n","source_id ref_epoch    ra   ...  bp_rp  phot_bp_rp_excess_factor\n","              yr      deg   ...   mag                           \n","  int64    float64  float64 ... float32         float32         \n","--------- --------- ------- ... ------- ------------------------"],"text/html":["<div><i>Table length=0</i>\n","<table id=\"table139682134726160\" class=\"table-striped table-bordered table-condensed\">\n","<thead><tr><th>source_id</th><th>ref_epoch</th><th>ra</th><th>ra_error</th><th>dec</th><th>dec_error</th><th>parallax</th><th>parallax_error</th><th>parallax_over_error</th><th>pmra</th><th>pmra_error</th><th>pmdec</th><th>pmdec_error</th><th>radial_velocity</th><th>radial_velocity_error</th><th>astrometric_params_solved</th><th>visibility_periods_used</th><th>astrometric_sigma5d_max</th><th>ruwe</th><th>phot_g_mean_mag</th><th>phot_g_mean_flux_over_error</th><th>phot_bp_mean_mag</th><th>phot_bp_mean_flux_over_error</th><th>phot_rp_mean_mag</th><th>phot_rp_mean_flux_over_error</th><th>bp_rp</th><th>phot_bp_rp_excess_factor</th></tr></thead>\n","<thead><tr><th></th><th>yr</th><th>deg</th><th>mas</th><th>deg</th><th>mas</th><th>mas</th><th>mas</th><th></th><th>mas / yr</th><th>mas / yr</th><th>mas / yr</th><th>mas / yr</th><th>km / s</th><th>km / s</th><th></th><th></th><th>mas</th><th></th><th>mag</th><th></th><th>mag</th><th></th><th>mag</th><th></th><th>mag</th><th></th></tr></thead>\n","<thead><tr><th>int64</th><th>float64</th><th>float64</th><th>float32</th><th>float64</th><th>float32</th><th>float64</th><th>float32</th><th>float32</th><th>float64</th><th>float32</th><th>float64</th><th>float32</th><th>float32</th><th>float32</th><th>int16</th><th>int16</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th></tr></thead>\n","</table></div>"]},"metadata":{},"execution_count":25}],"source":["# # Read in WDS (from Vayu's Lab comp)\n","#path = 'C:/Users/sc36/Documents/DaphneUSNO/NOFS copy-20230218T215456Z-001/NOFS copy/wdstab6-27.ecsv'\n","#wdstab = Table.read(path, header_start=0, data_start=1) \n","\n","\n","rownum = 754\n","\n","#read in the coordinates of the primary and secondary in WDS for the designated row number\n","ra1, dec1 = wdstab['RApri-prepped'][rownum], wdstab['DECpri-prepped'][rownum]\n","ra2, dec2 = wdstab['RAsec-prepped'][rownum], wdstab['DECsec-prepped'][rownum]\n","# radius is degrees\n","radius = 5*u.arcsec\n","coord1 = SkyCoord(ra=ra1 , dec = dec1, unit='deg')\n","myquery1 = query_gaia(coordinate=coord1, radius=radius)\n","\n","radius = 5*u.arcsec\n","coord2 = SkyCoord(ra=ra2 , dec = dec2, unit='deg')\n","myquery2 = query_gaia(coordinate=coord2, radius=radius)\n","\n","\n","vstack([myquery1, myquery2])\n"]},{"cell_type":"markdown","id":"2984fc72","metadata":{"id":"2984fc72"},"source":["## wds_in_gaia_query(core_num, total_cores) --- query WDS entries in Gaia and save results in a table"]},{"cell_type":"code","execution_count":null,"id":"ed417caf","metadata":{"id":"ed417caf"},"outputs":[],"source":["def wds_in_gaia_query(core_num, total_cores): # core num starts at 0 \n","    \n","    # # Read in WDS from Vayu's Lab\n","    path = 'C:/Users/sc36/Documents/DaphneUSNO/NOFS copy-20230218T215456Z-001/NOFS copy/wdstab6-27.ecsv'\n","    wdstab = Table.read(path, header_start=0, data_start=1) \n","\n","    # total number of queries will be the number of wds entries that we look at\n","    total_num_queries = len(wdstab)\n","    \n","    # find approx # of queries per core... ignoring the fraction \n","    queries_per_core = total_num_queries // total_cores\n","    leftover_rows = total_num_queries % total_cores\n","\n","\n","    # make a list of the start and end row variables0\n","    start_row_list = []\n","    end_row_list = []\n","\n","    # make a list to get the start and end row for each process\n","    rownum_counter = 0\n","    for core in range(total_cores):\n","        start_row_list.append(rownum_counter)\n","        rownum_counter += queries_per_core\n","        if core == total_cores - 1:\n","            end_row_list.append(total_num_queries)\n","        else:\n","            end_row_list.append(rownum_counter)\n","    end_row_list[-1] = end_row_list[-1] + leftover_rows\n","    \n","    \n","    # define start and end row of wds\n","    # start row is included in query, but end row is not included in the range\n","    wds_start_row =  start_row_list[core_num]\n","    wds_end_row = end_row_list[core_num]\n","    \n","    \n","\n","    # these are the column names that have a number data type... \n","    # the source ids need to stay as strings so I add those separately\n","    num_column_names = ['ref_epoch', 'ra', 'ra_error', 'dec',\n","                    'dec_error', 'parallax', 'parallax_error', 'parallax_over_error','pmra',\n","                    'pmra_error', 'pmdec', 'pmdec_error',\n","                    'radial_velocity', 'radial_velocity_error',\n","                    'astrometric_params_solved', 'visibility_periods_used',\n","                    'astrometric_sigma5d_max','ruwe',\n","                    'phot_g_mean_mag', 'phot_g_mean_flux_over_error',\n","                    'phot_bp_mean_mag', 'phot_bp_mean_flux_over_error',\n","                    'phot_rp_mean_mag', 'phot_rp_mean_flux_over_error',\n","                    'bp_rp','phot_bp_rp_excess_factor']\n","\n","       \n","\n","    \n","\n","    # we will have a pair of stars for each column\n","    # put the parameters in a dictionary with suffixes _a and _b to name columns accordingly\n","    colname_dictionary = {}\n","\n","    for column in num_column_names:\n","        colname_dictionary['{0}_a'.format(column)] = 0\n","        colname_dictionary['{0}_b'.format(column)] = 0\n","\n","    colnames = []\n","    for entry in colname_dictionary:\n","        colnames.append(entry)\n","    \n","    \n","        \n","        \n","    \"\"\" BUILD OUTPUT TABLES \"\"\"\n","    \n","    # query results table will have all info for a pair of stars in one row\n","    query_results_table = Table(names=colnames)\n","    \n","    \n","    # add the wds identifier column and source id columns (doesn't work until I add one row to the table)\n","    query_results_table.add_row()\n","    query_results_table.add_column('                              ', name = 'wds_identifier', index = 0)\n","    query_results_table.add_column('                              ', name = 'source_id_a', index = 1)\n","    query_results_table.add_column('                              ', name = 'source_id_b', index = 2)\n","\n","    \n","    # remove that first row -- the loop will add rows as needed\n","    query_results_table.remove_row(0)\n","    \n","    \n","    \n","    # index error wds info:\n","    index_error_queries = Table(names = ('wds_identifier', 'wds_rownum'), dtype = ('a30', 'f8'))\n","    \n","    # unknown error wds info:\n","    unknown_error_queries = Table(names = ('wds_identifier', 'wds_rownum'), dtype = ('a30', 'f8'))\n","    \n","    \n","    \n","    \n","    # initialize row numbers for each output table:\n","    query_results_table_rownum = 0\n","    index_error_queries_rownum = 0\n","    unknown_error_queries_rownum = 0\n","        \n","    \n","    \n","  \n","    \n","    \n","    # initialize wds identifier\n","    wds_identifier = ''\n","    \n","    \n","\n","    for rownum in range(wds_start_row, wds_end_row):   \n","        \n","        # if the previous WDS identifier (from last iteration of loop) is the same is current one,\n","        # this row was already accounted for in that query\n","        if wdstab['WDS Identifier'][rownum] == wds_identifier:\n","            pass\n","        \n","        else:    \n","            # read in the wds identifier so we know which object is queried\n","            wds_identifier = wdstab['WDS Identifier'][rownum]\n","            \n","            # if there are multiple columns with same WDS identifier, \n","            # query all of those objects and add them to gaiaresults list\n","            for shared_id_rownum in range(rownum, wds_end_row):\n","                if wdstab['WDS Identifier'][shared_id_rownum] == wds_identifier:\n","            \n","                    print('\\n core # ', core_num, 'of ', total_cores, 'cores   --- row number: ', rownum)\n","                    \"\"\" make the 2 queries for given WDS row \"\"\"\n","                    # use query_gaia(coordinate, radius) to query gaia server\n","                    ra1, dec1, ra2, dec2 =wdstab['RApri-prepped'][rownum], wdstab['DECpri-prepped'][rownum], wdstab['RAsec-prepped'][rownum], wdstab['DECsec-prepped'][rownum]\n","                    \n","                    radius1 = 5*u.arcsec\n","                    coord = SkyCoord(ra=ra1 , dec = dec1, unit='deg')\n","                    myquery1 = query_gaia(coordinate=coord, radius=radius1)\n","                    \n","                    radius2 = 5*u.arcsec\n","                    coord = SkyCoord(ra=ra2 , dec = dec2, unit='deg')\n","                    myquery2 = query_gaia(coordinate=coord, radius=radius2)\n","                    \n","                    \"\"\" VERTICALLY STACK ALL QUERIES TO CREATE A LIST WITH ALL QUERIES FROM 1 WDS ROW \"\"\"\n","                    \n","                    # first query for this WDS identifier: just add query 1 and 2 to list\n","                    \n","                    if len(myquery1) + len(myquery2) == 0: \n","                        index_error_queries.add_row()\n","                        index_error_queries['wds_identifier'][index_error_queries_rownum] = wds_identifier\n","                        index_error_queries['wds_rownum'][index_error_queries_rownum] = rownum\n","                        index_error_queries_rownum +=1\n","\n","                        # checkpoint\n","                        # print('index error table updated')\n","                        pass\n","                    elif shared_id_rownum == rownum:\n","                        gaiaresults = vstack([myquery1, myquery2])\n","                        \n","                    # then, keep adding the new queries to the existing gaiaresults list\n","                    else:\n","                        gaiaresults = vstack([gaiaresults, myquery1, myquery2])\n","                        \n","              \n","                    \n","                # if WDS identifiers don't match, move on\n","                else:\n","                    pass\n","                \n","\n","            try:\n","\n","                \"\"\" REMOVE DUPLICATES FROM GAIA RESULTS TABLE \"\"\"\n","\n","                # checkpoint\n","                # print('length of gaiaresults is', len(gaiaresults))\n","\n","                gaiaresults = unique(gaiaresults, keep = 'first', silent = 'True')\n","\n","                # checkpoint\n","                # print('duplicates_removed')\n","                # print('length of gaiaresults is', len(gaiaresults))\n","\n","                # save all query results where less than two unique objects are found\n","                # to index error query table\n","\n","                if len(gaiaresults) <= 1:\n","                    index_error_queries.add_row()\n","                    index_error_queries['wds_identifier'][index_error_queries_rownum] = wds_identifier\n","                    index_error_queries['wds_rownum'][index_error_queries_rownum] = rownum\n","                    index_error_queries_rownum +=1\n","\n","                    # checkpoint\n","                    # print('index error table updated')\n","                    pass\n","\n","\n","                else:\n","\n","\n","                    \"\"\" CROSS CHECK EACH ENTRY WITH EACH OTHER \"\"\"\n","                    # avoid repeat comparisons\n","\n","                    # make a list of every unique combination of two objects in my list\n","                    # this will be a comma separate string of source ids from Gaia\n","                    L = gaiaresults['source_id']\n","                    combolist = [\",\".join(map(str, comb)) for comb in combinations(L, 2)]\n","\n","                    # checkpoint\n","                    # print('cross check complete')\n","\n","\n","                    #make source id column the index for gaiaresults table\n","                    # this allows us to return a row by searching the source id \n","                    gaiaresults.add_index('source_id')\n","\n","\n","                    # use the list of unique combinations and find both of those rows\n","                    # then, compare them\n","\n","\n","\n","                    for combination in combolist:\n","\n","\n","                        # the combination is a comma separated entry of two source ids -- unique combo\n","                        # then, split them up so I can call to the data about each specific target in the combo\n","                        # the source id is the index for my gaiaresults table, so I can call to the target row using the id\n","                        query_a, query_b = combination.split(',')\n","                        row_a = gaiaresults.loc[int(query_a)]\n","                        row_b = gaiaresults.loc[int(query_b)]\n","\n","                        # checkpoint\n","                        # print('components assigned')\n","                        # print(gaiaresults)\n","                        \n","                        \"\"\" READ IN THE RELEVANT INFO (source id and parallax): \"\"\"\n","\n","                        # read in the parameters for object a and b\n","                        # put the parameters in a dictionary with suffixes _a and _b accordingly\n","                        parameter_dictionary = {}\n","\n","                        for column in query_results_table.colnames:\n","                            if column == 'wds_identifier':\n","                                parameter_dictionary['wds_identifier'] = wdstab[rownum]['WDS Identifier']\n","\n","                            elif column.endswith('_a') == True:\n","                                param_len = len(column)\n","                                parameter_dictionary['{0}'.format(str(column))] = row_a[column[:param_len - 2]]\n","                            elif column.endswith('_b') == True:\n","                                param_len = len(column)\n","                                parameter_dictionary['{0}'.format(str(column))] = row_b[column[:param_len - 2]]\n","\n","\n","\n","                        query_results_table.add_row()\n","\n","                        for entry in parameter_dictionary:\n","                            query_results_table[entry][query_results_table_rownum] = parameter_dictionary[entry]\n","\n","\n","                        query_results_table_rownum +=1\n","\n","                        # checkpoint\n","                        # print('query_results_table updated')\n","\n","\n","\n","\n","            except:\n","                # make a list of objects with any other error:           \n","                unknown_error_queries.add_row()\n","                unknown_error_queries['wds_identifier'][unknown_error_queries_rownum] = wds_identifier\n","                unknown_error_queries['wds_rownum'][unknown_error_queries_rownum] = rownum\n","                unknown_error_queries_rownum +=1\n","                \n","                #checkpoint\n","                # print('unknown error')\n","                \n","                pass\n","\n","\n","                \n","    save_path = 'C:/Users/sc36/Documents/DaphneUSNO/NOFS copy-20230218T215456Z-001/NOFS copy/QueryResults'\n","    ascii.write(query_results_table, '{path}/query_results_table_c{core}.ecsv'.format(path = save_path, core = core_num), format='ecsv',overwrite=True)\n","    ascii.write(query_results_table, '{path}/query_results_table_c{core}.csv'.format(path = save_path, core = core_num), format='csv',overwrite=True)\n","    \n","    ascii.write(index_error_queries, '{path}/index_error_queries_c{core}.ecsv'.format(path = save_path, core = core_num), format='ecsv',overwrite=True)\n","    ascii.write(index_error_queries, '{path}/index_error_queries_c{core}.csv'.format(path = save_path, core = core_num), format='csv',overwrite=True)\n","    \n","    ascii.write(unknown_error_queries, '{path}/unknown_error_queries_c{core}.ecsv'.format(path = save_path, core = core_num), format='ecsv',overwrite=True)\n","    ascii.write(unknown_error_queries, '{path}/unknown_error_queries_c{core}.csv'.format(path = save_path, core = core_num), format='csv',overwrite=True)\n","    "]},{"cell_type":"code","execution_count":null,"id":"20e98c53","metadata":{"id":"20e98c53"},"outputs":[],"source":["\n","\n","# wds_in_gaia_query(0,30000)\n","# wds_in_gaia_query(1,30000)\n","# wds_in_gaia_query(2,30000)\n","# wds_in_gaia_query(3,30000)\n","\n"]},{"cell_type":"markdown","id":"2e100676","metadata":{"id":"2e100676"},"source":["\n","### Dividing up the WDS for multiprocessing\n","##### this is incorporated in the main function, just rewritten here for checks"]},{"cell_type":"code","execution_count":null,"id":"0213e9b2","metadata":{"id":"0213e9b2"},"outputs":[],"source":["# Prepare for multiprocessing\n","total_cores = 2\n","\n","# total number of queries will be the number of wds entries that we look at\n","total_num_queries = len(wdstab)\n","\n","# find approx # of queries per core... ignoring the fraction \n","queries_per_core = total_num_queries // total_cores\n","leftover_rows = total_num_queries % total_cores\n","\n","# make a list of the start and end row variables0\n","start_row_list = []\n","end_row_list = []\n","\n","# make a list to get the start and end row for each process\n","rownum_counter = 0\n","for core in range(total_cores):\n","    start_row_list.append(rownum_counter)\n","    rownum_counter += queries_per_core\n","    if core == total_cores - 1:\n","        end_row_list.append(total_num_queries)\n","    else:\n","        end_row_list.append(rownum_counter)\n","\n","end_row_list[-1] = end_row_list[-1] + leftover_rows\n","\n","\n"]},{"cell_type":"markdown","id":"6c016f44","metadata":{"id":"6c016f44"},"source":["## Initiate Gaia Query with multiprocessing"]},{"cell_type":"code","execution_count":null,"id":"1995dbc2","metadata":{"id":"1995dbc2"},"outputs":[],"source":["\n","def initiate_gaia_query(total_cores):\n","    processes=[]\n","    \n","    queue = Queue()\n","    for core_num in range(total_cores):\n","        p = multiprocessing.Process(target = wds_in_gaia_query, args = (core_num, total_cores))\n","        p.start()\n","        processes.append(p)\n","    \n","    for p in processes:\n","        p.join()\n"]},{"cell_type":"markdown","id":"cf145e98","metadata":{"id":"cf145e98"},"source":["## Test query multiprocessing"]},{"cell_type":"code","execution_count":null,"id":"f538c0a9","metadata":{"id":"f538c0a9"},"outputs":[],"source":["def initiate_test_gaia_query():\n","\n","        \n","    processes=[]\n","    \n","    num_of_processes = 4\n","    divide_wds = 3000\n","    \n","    queue = Queue()\n","    for core_num in range(num_of_processes):\n","        print('process initiated: core', core_num)\n","        p = multiprocessing.Process(target = wds_in_gaia_query, args = (core_num, divide_wds))\n","        p.start()\n","        processes.append(p)\n","        \n","\n","    for p in processes:\n","        p.join()\n"]},{"cell_type":"code","execution_count":null,"id":"00061a3f","metadata":{"id":"00061a3f","outputId":"3ec50042-0f7c-4427-def7-69e1afe6f247"},"outputs":[{"name":"stdout","output_type":"stream","text":["process initiated: core 0\n","process initiated: core 1\n","process initiated: core 2\n","process initiated: core 3\n"]}],"source":["initiate_test_gaia_query()"]},{"cell_type":"code","execution_count":null,"id":"c35f9cf0","metadata":{"id":"c35f9cf0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"7e5ec9e4","metadata":{"id":"7e5ec9e4"},"outputs":[],"source":["\n","\n","# if __name__ == '__main__':\n","#     pool = Pool()\n","#     divide_wds = 3000                         # Create a multiprocessing Pool\n","#     for core_num in range(4):\n","#         pool.map(wds_in_gaia_query,core_num, divide_wds)  # process data_inputs iterable with pool \n","        \n","    "]},{"cell_type":"code","execution_count":null,"id":"22fb8ddd","metadata":{"id":"22fb8ddd"},"outputs":[],"source":["if __name__ == '__main__':\n","    list_of_cores = [0,1,2]\n","    for i in list_of_cores:\n","        p = Process(target=wds_in_gaia_query, args = (i, 50000,))\n","        p.start()\n","        print('Waiting for simple func to end')\n","        p.join()\n","\n","\n","# ### stack output files "]},{"cell_type":"code","execution_count":null,"id":"1613ebd8","metadata":{"id":"1613ebd8"},"outputs":[],"source":["# file_dictionary = {}\n","\n","# total_cores = 4\n","\n","# for core_num in range(total_cores):\n","\n","#             file_dictionary['query_results_table_c{0}'.format(core_num)] = 0\n","#             file_dictionary['index_error_queries_c{0}'.format(core_num)] = 0\n","            \n","            \n","\n","# directory = 'C:/Users/sc36/Documents/DaphneUSNO/NOFS copy-20230218T215456Z-001/NOFS copy/QueryResults'\n","\n","# for file in file_dictionary:\n","    \n","#     file_dictionary[file] = Table.read('{0}/{1}.ecsv'.format(directory, file), header_start=0, data_start=1)\n","    \n","\n","    \n","    \n","\n","# # vertically stack all 20 sections of each table\n","\n","\n","# query_results_table_list = []\n","# index_error_queries_list = []\n","\n","\n","# for file in file_dictionary:\n","#     if file.startswith('query_results_table_c'):\n","#         query_results_table_list.append(file_dictionary[file])\n","#     elif file.startswith('index_error_queries_c'):\n","#         index_error_queries_list.append(file_dictionary[file])\n","\n","\n","\n","# stack_query_results_table = vstack(query_results_table_list)\n","# stack_index_error_queries = vstack(index_error_queries_list)\n","\n","\n","# ascii.write(stack_query_results_table, '{0}/stack_query_results_table.ecsv'.format(directory), format='ecsv')\n","# ascii.write(stack_query_results_table, '{0}/stack_query_results_table.csv'.format(directory), format='csv')\n","\n","\n","# ascii.write(stack_index_error_queries, '{0}/stack_index_error_queries.ecsv'.format(directory), format='ecsv')\n","# ascii.write(stack_index_error_queries, '{0}/stack_index_error_queries.csv'.format(directory), format='csv')\n","\n","\n","# qrt ='{0}/stack_query_results_table.ecsv'.format(directory) \n","# ie = '{0}/stack_index_error_queries.ecsv'.format(directory)\n","# stack_query_results_table = Table.read(qrt, header_start=0, data_start=1)\n","# stack_index_error_queries = Table.read(ie, header_start=0, data_start=1)\n","\n","\n","\n","\n","\n","# # In[13]:"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}